{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUfJR9B7Qspu",
        "outputId": "4db469ba-bed0-4aee-9a0d-a51974580811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.7.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text\n",
        "!pip install tensorflow_addons\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6jwAUk4QUfS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnTQ6G84QUfW"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An3WB2q8QUfW",
        "outputId": "28b79671-a50a-499b-a172-ecad64102a6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AhUZnUO0QUfX",
        "outputId": "630361f7-4dac-4c15-9d42-6e363005235d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Content</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Ah, it's the weekend again. This has become a ...</td>\n",
              "      <td>Fulfilled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It was hectic. Then on top of that the one and...</td>\n",
              "      <td>Unfulfilled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Being a groomsman, I really didn't get the cha...</td>\n",
              "      <td>Fulfilled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Before justice started school I had an idea to...</td>\n",
              "      <td>Fulfilled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>So for some reason (I dunno wad) I was under t...</td>\n",
              "      <td>Unfulfilled</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                            Content        Label\n",
              "0           0  Ah, it's the weekend again. This has become a ...    Fulfilled\n",
              "1           1  It was hectic. Then on top of that the one and...  Unfulfilled\n",
              "2           2  Being a groomsman, I really didn't get the cha...    Fulfilled\n",
              "3           3  Before justice started school I had an idea to...    Fulfilled\n",
              "4           4  So for some reason (I dunno wad) I was under t...  Unfulfilled"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "df = pd.read_csv(\"DesireDBPreprocessed.csv\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zrt0rysqQUfY",
        "outputId": "15b65511-b45a-4746-8709-11a059df0160"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">Unnamed: 0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Fulfilled</th>\n",
              "      <td>1950.0</td>\n",
              "      <td>1915.909744</td>\n",
              "      <td>1052.956578</td>\n",
              "      <td>0.0</td>\n",
              "      <td>992.50</td>\n",
              "      <td>1968.5</td>\n",
              "      <td>2854.75</td>\n",
              "      <td>3586.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unfulfilled</th>\n",
              "      <td>1126.0</td>\n",
              "      <td>1633.002664</td>\n",
              "      <td>946.576897</td>\n",
              "      <td>1.0</td>\n",
              "      <td>851.50</td>\n",
              "      <td>1590.5</td>\n",
              "      <td>2365.75</td>\n",
              "      <td>3587.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unknown</th>\n",
              "      <td>512.0</td>\n",
              "      <td>1680.259766</td>\n",
              "      <td>1097.551201</td>\n",
              "      <td>6.0</td>\n",
              "      <td>643.25</td>\n",
              "      <td>1618.5</td>\n",
              "      <td>2730.50</td>\n",
              "      <td>3584.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Unnamed: 0                            ...                         \n",
              "                 count         mean          std  ...     50%      75%     max\n",
              "Label                                             ...                         \n",
              "Fulfilled       1950.0  1915.909744  1052.956578  ...  1968.5  2854.75  3586.0\n",
              "Unfulfilled     1126.0  1633.002664   946.576897  ...  1590.5  2365.75  3587.0\n",
              "Unknown          512.0  1680.259766  1097.551201  ...  1618.5  2730.50  3584.0\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "df.groupby('Label').describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQf48XEVQUfY",
        "outputId": "c0352cb7-896d-4101-df7f-743151fac149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fulfilled      1950\n",
              "Unfulfilled    1126\n",
              "Unknown         512\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMZ7cFZSQUfZ"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:, 1 :-1].values\n",
        "y = df.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu8TcAm8QUfZ"
      },
      "outputs": [],
      "source": [
        "LABELS = [\n",
        "    'admiration',\n",
        "    'amusement',\n",
        "    'anger',\n",
        "    'annoyance',\n",
        "    'approval',\n",
        "    'caring',\n",
        "    'confusion',\n",
        "    'curiosity',\n",
        "    'desire',\n",
        "    'disappointment',\n",
        "    'disapproval',\n",
        "    'disgust',\n",
        "    'embarrassment',\n",
        "    'excitement',\n",
        "    'fear',\n",
        "    'gratitude',\n",
        "    'grief',\n",
        "    'joy',\n",
        "    'love',\n",
        "    'nervousness',\n",
        "    'optimism',\n",
        "    'pride',\n",
        "    'realization',\n",
        "    'relief',\n",
        "    'remorse',\n",
        "    'sadness',\n",
        "    'surprise',\n",
        "    'neutral',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxeejvRlQUfb"
      },
      "outputs": [],
      "source": [
        "def values_to_label(values):\n",
        "\n",
        "  maxim = -1 \n",
        "  index = -1\n",
        "\n",
        "  for i in range(len(values)):\n",
        "    if values[i] > maxim: \n",
        "      maxim = values[i] \n",
        "      index = i\n",
        "\n",
        "  # print(LABELS[index])\n",
        "\n",
        "  return LABELS[index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1ZvY7uKQUfc"
      },
      "outputs": [],
      "source": [
        "X_with_emotion = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhI8tLnvQUfc"
      },
      "outputs": [],
      "source": [
        "with open('out_visual.pickle', 'rb') as fd:\n",
        "    w = pickle.load(fd)\n",
        "\n",
        "    for i in range(len(X)):\n",
        "\n",
        "      label = values_to_label(w[i][1])\n",
        "      x_simple = X[i].tolist()\n",
        "      x_simple[0] = x_simple[0] + \" \" + label\n",
        "      X_with_emotion.append(x_simple)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xap2JDKQUfd"
      },
      "outputs": [],
      "source": [
        "markers = {\"accordingly\": 0, \"so\": 0,\"ultimately\": 0,\"finally\": 0, \"rather\": 0, \"yet\": 0, \"although\": 0, \"but\": 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdBTbAuMQUfd"
      },
      "outputs": [],
      "source": [
        "for story in X_with_emotion:\n",
        "  word_list = story[0].split()\n",
        "  for word in word_list:\n",
        "    if word in markers:\n",
        "      markers[word] += 1\n",
        "  story[0] += \" \"+str(sum(list(markers.values())[:4]))\n",
        "  story[0] += \" \"+str(sum(list(markers.values())[-4:]))\n",
        "\n",
        "  markers = {k: 0 for k in markers}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNsDdEXKdzwL",
        "outputId": "971b0db7-4a99-4ac5-c4aa-08aa2531c3a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accordingly': 0,\n",
              " 'although': 0,\n",
              " 'but': 0,\n",
              " 'finally': 0,\n",
              " 'rather': 0,\n",
              " 'so': 0,\n",
              " 'ultimately': 0,\n",
              " 'yet': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "markers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XspnsVc5QUfd",
        "outputId": "b420558d-cb67-42c5-f26d-0c2fc9dcceb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"Ah, it's the weekend again. This has become a sort of weekend blog, hasn't it? For Saturday morning's activity, I decided to organize a small team for trekking the nice and simple route of Kranji Memorial trek once again. However, as the weather gods would have it, I woke up to ominous looking skies. Soon, it started pouring and one by one, people decided to back out. Finally, only Jane, Felix, Jervais and I were left. But hey, the weather turned out to be really awsome! Raving to go, people! neutral 0 0\"],\n",
              " [\"It was hectic. Then on top of that the one and ONLY day I have ever worn a skirt and pantyhose to work, I had to spend the afternoon crawling on the floor under my desk plugging shit in. I am not a dressy person, I don't like dresses and skirts. I would much rather wear pants, and I certainly do not like pantyhoes or stockings of any kind. But I live in the south, and ladies are expected to wear them if they are showing any leg at all, it is just not socially acceptable in my office not to do so. Also, I had super intentions of going to bed at like 9 tonight, but then matt IMed me wanted to talk, and the Sox/Yanks game was on, and I still haven't decided what I am going to wear tomorrow because again, I was under the impression that tomorrow was Friday and I could wear jeans because it was casual day. But no, tricksters and all, it's Thursday so I have to pull one more nice outfit and heels out of my ass for another day. And I have to come up with it now, because I am not to be trusted to do so in a timely manner in the mornings. I just am beginning to hate getting dressed more and more each day. disapproval 2 2\"]]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "X_with_emotion[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGWnIepci1VS"
      },
      "outputs": [],
      "source": [
        "X_with_emotion = [x for x,label in zip(X_with_emotion,y) if label =='Fulfilled' or label =='Unfulfilled']\n",
        "y = [label for label in y if label =='Fulfilled' or label =='Unfulfilled']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8gkUttTQUfe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_with_emotion,y,test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOwv9t3N8XLL",
        "outputId": "3aee61aa-bbaa-4c31-c24b-e72ab17da070"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2460"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXyL9L1RQUfe"
      },
      "outputs": [],
      "source": [
        "label_to_id= {'Fulfilled' : 0, 'Unfulfilled' : 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S9rKHbzQUff"
      },
      "outputs": [],
      "source": [
        "y_train = [label_to_id[label] for label in y_train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkCCc0HHQUff"
      },
      "outputs": [],
      "source": [
        "y_train = tf.one_hot(y_train, depth = 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = [label_to_id[label] for label in y_test]\n",
        "y_test = tf.one_hot(y_test, depth = 2)"
      ],
      "metadata": {
        "id": "HN5ntWdACagA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVki1FtYeANz",
        "outputId": "1f533754-96ef-43b3-d251-c5c6ef4a45ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2460, 2), dtype=float32, numpy=\n",
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC5dyj8DQUfg"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHpe4ugIuifR"
      },
      "outputs": [],
      "source": [
        "def batch_encode(tokenizer, texts, batch_size=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for x in texts:\n",
        "      x = tokenizer(x, return_tensors='tf', truncation=True, padding=True, pad_to_multiple_of=512)  # to cut sentences with > 512 words\n",
        "      input_ids.append(x['input_ids'])\n",
        "      attention_masks.append(x['attention_mask'])\n",
        "\n",
        "    # return tf.convert_to_tensor(h), tf.convert_to_tensor(np.array(attention_masks))\n",
        "    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_masks)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDI7ElIHuhT8"
      },
      "outputs": [],
      "source": [
        "from transformers import  DistilBertTokenizer, DistilBertModel\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Encode X_train\n",
        "X_train_ids, X_train_attention = batch_encode(tokenizer, X_train)\n",
        "\n",
        "# Encode X_test\n",
        "X_test_ids, X_test_attention = batch_encode(tokenizer, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dnDkVlPv_DQ",
        "outputId": "5591a7b6-61bc-4891-f123-0a56741dc9fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  101  2002  2001 15261  2012  1996  4511  1010  1996  2833  1010  1996\n",
            "   8012  1997  1996 12846  2008  2134  2102  3599  5574  2000  2026  5510\n",
            "   8569  5104  1010  2021  2009  2428  2106  2007  2010  1012  2673  1045\n",
            "   3740  2001  2005  2032  1010  2009  2790  2130  2026  3745  1997  2833\n",
            "   2036  2001  2005  2032  1012  5292  3270  1012  2061  2172  2005  2771\n",
            "   1010  1045  2347  2102  8510  2007  1996  2833  1045  2245  1997 13063\n",
            "  26666  2000  2191  2870  3407  1012  2021  1045  2134  2102  1012  2044\n",
            "   4596  1010  2904  1999  2000  2026 20345  1010  1998  2253 14855 10841\n",
            "  13793  2007 14006  1010  1998  2062 14006  2008  2057  1031  7303  1033\n",
            "   2005  2138  1045  2001  4452  1997  1996  2601  1012  1045  4711  3123\n",
            "  15829  1999  1996  2300  1012  2009  2001  2428 11895  6559  1012  5292\n",
            "   3270  1012  2064  2102  6235  2009  2012  2305  1012  2049  2061  2367\n",
            "   1999  1996  2154  1012  6298  3325  2008  3383  2028  2154  1045  2097\n",
            "   5293  2138  1045  3685  2404  1996  4751  2091  2182  1012  6226  1015\n",
            "   1015   102     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]], shape=(1, 512), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0]], shape=(1, 512), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[  101  3407  5095  3071   999   999  1045  2074  2359  2000  4339  1037\n",
            "   4248  2695  2000  2292  2017  2113  2055  2035  1996  8277  1045  1005\n",
            "   2310  2018  2061  2521  2023  5353  1012  3342  2043  1045  2056  2026\n",
            "   2166  2323  2022  2081  2046  1037  4507  2265  1029  2009  2428  2323\n",
            "   1012  1012  1012  2061  7483  2044  2147  1045  2777  9734  1010 13675\n",
            "   7416 21763  1998  2070  2500  5116  2005  3407  3178  1998  2059  2000\n",
            "   2175  2156  1996  2316  2101  1012  1045  2018  1037  2843  2205  2172\n",
            "   4569  1998  2347  1005  1056  2583  2000  3298  2188  2061  1045  2288\n",
            "   1037  4536  2013  9734  1004 13675  7416 21763  1006  4283  2153  4364\n",
            "    999  1007  1012  1045  2018  5070  2050  2202  2033  5116  2000  2131\n",
            "   2026  2482  2023  2851  1012  6569  1016  1014   102     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]], shape=(1, 512), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0]], shape=(1, 512), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "print(X_train_ids[0])\n",
        "print(X_train_attention[0])\n",
        "print(X_test_ids[0])\n",
        "print(X_test_attention[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymrxSsSTQUfh"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      'accuracy',\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4bdcdqvQaQB"
      },
      "outputs": [],
      "source": [
        "def unfreeze_model(model):\n",
        "    # Used for fine-tuning the model\n",
        "    for layer in model.layers[-100:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns4OTloztAOM",
        "outputId": "68adad43-7746-4048-f073-3e11c037bc4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_projector', 'vocab_layer_norm', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFDistilBertModel, DistilBertConfig\n",
        "\n",
        "DISTILBERT_DROPOUT = 0.2\n",
        "DISTILBERT_ATT_DROPOUT = 0.2\n",
        " \n",
        "# Configure DistilBERT's initialization\n",
        "config = DistilBertConfig(dropout=DISTILBERT_DROPOUT, \n",
        "                          attention_dropout=DISTILBERT_ATT_DROPOUT, \n",
        "                          output_hidden_states=True)\n",
        "\n",
        "LAYER_DROPOUT = 0.2\n",
        "LEARNING_RATE = 3e-5\n",
        "RANDOM_STATE = 1\n",
        "\n",
        "init_lr = 5e-3\n",
        "# # optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    init_lr,\n",
        "    decay_steps=300,\n",
        "    decay_rate=0.75,\n",
        "    staircase=True)\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "transformer_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=config)\n",
        "transformer_model.trainable = False\n",
        "transformer_model = unfreeze_model(transformer_model)\n",
        "\n",
        "weight_initializer = tf.keras.initializers.GlorotNormal(seed=RANDOM_STATE)\n",
        "\n",
        "def build_classifier_model_ft(transformer):\n",
        "  input_ids_layer = tf.keras.layers.Input(shape=(512,), \n",
        "                                            name='input_ids', \n",
        "                                            dtype='int32')\n",
        "  input_attention_layer = tf.keras.layers.Input(shape=(512,), \n",
        "                                                  name='input_attention', \n",
        "                                                  dtype='int32')\n",
        "    \n",
        "  last_hidden_state = transformer([input_ids_layer, input_attention_layer])[0]\n",
        "  \n",
        "  cls_token = last_hidden_state[:, 0, :]\n",
        "\n",
        "  output = tf.keras.layers.Dense(2, activation='sigmoid', \n",
        "                                 kernel_initializer=weight_initializer,  kernel_constraint=None,\n",
        "                                 bias_initializer='zeros')(cls_token)\n",
        "\n",
        "  model = tf.keras.Model([input_ids_layer, input_attention_layer], output)\n",
        "  model.compile(tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss=loss, metrics=METRICS)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = build_classifier_model_ft(transformer_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fsdD2cWwtPp"
      },
      "outputs": [],
      "source": [
        "X_train_ids_1 = tf.convert_to_tensor([o[0] for o in X_train_ids])\n",
        "X_train_attention_1 = tf.convert_to_tensor([o[0] for o in X_train_attention])\n",
        "X_test_ids_1 = tf.convert_to_tensor([o[0] for o in X_test_ids])\n",
        "X_test_attention_1 = tf.convert_to_tensor([o[0] for o in X_test_attention])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnaJE20BuMUQ",
        "outputId": "1b74b357-4438-4557-9dc4-af736afbec24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_attention (InputLayer)   [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_distil_bert_model_4 (TFDist  TFBaseModelOutput(l  66362880   ['input_ids[0][0]',              \n",
            " ilBertModel)                   ast_hidden_state=(N               'input_attention[0][0]']        \n",
            "                                one, 512, 768),                                                   \n",
            "                                 hidden_states=((No                                               \n",
            "                                ne, 512, 768),                                                    \n",
            "                                 (None, 512, 768),                                                \n",
            "                                 (None, 512, 768),                                                \n",
            "                                 (None, 512, 768),                                                \n",
            "                                 (None, 512, 768),                                                \n",
            "                                 (None, 512, 768),                                                \n",
            "                                 (None, 512, 768)),                                               \n",
            "                                 attentions=None)                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  (None, 768)         0           ['tf_distil_bert_model_4[0][7]'] \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 2)            1538        ['tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,364,418\n",
            "Trainable params: 1,538\n",
            "Non-trainable params: 66,362,880\n",
            "__________________________________________________________________________________________________\n",
            "2460\n",
            "2460\n",
            "Epoch 1/35\n",
            "77/77 [==============================] - 104s 1s/step - loss: 0.6532 - accuracy: 0.6366 - precision: 0.6257 - recall: 0.6382\n",
            "Epoch 2/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.6356 - accuracy: 0.6463 - precision: 0.6445 - recall: 0.6472\n",
            "Epoch 3/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.6279 - accuracy: 0.6537 - precision: 0.6502 - recall: 0.6520\n",
            "Epoch 4/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.6126 - accuracy: 0.6711 - precision: 0.6665 - recall: 0.6654\n",
            "Epoch 5/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.6056 - accuracy: 0.6699 - precision: 0.6675 - recall: 0.6675\n",
            "Epoch 6/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.6014 - accuracy: 0.6646 - precision: 0.6633 - recall: 0.6630\n",
            "Epoch 7/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.6023 - accuracy: 0.6610 - precision: 0.6624 - recall: 0.6589\n",
            "Epoch 8/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5997 - accuracy: 0.6801 - precision: 0.6776 - recall: 0.6785\n",
            "Epoch 9/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5945 - accuracy: 0.6724 - precision: 0.6720 - recall: 0.6687\n",
            "Epoch 10/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.6092 - accuracy: 0.6711 - precision: 0.6695 - recall: 0.6703\n",
            "Epoch 11/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5942 - accuracy: 0.6748 - precision: 0.6753 - recall: 0.6748\n",
            "Epoch 12/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.6049 - accuracy: 0.6707 - precision: 0.6644 - recall: 0.6663\n",
            "Epoch 13/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5961 - accuracy: 0.6850 - precision: 0.6812 - recall: 0.6793\n",
            "Epoch 14/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5880 - accuracy: 0.6850 - precision: 0.6887 - recall: 0.6898\n",
            "Epoch 15/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5972 - accuracy: 0.6780 - precision: 0.6794 - recall: 0.6772\n",
            "Epoch 16/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5880 - accuracy: 0.6858 - precision: 0.6875 - recall: 0.6878\n",
            "Epoch 17/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5818 - accuracy: 0.6878 - precision: 0.6891 - recall: 0.6911\n",
            "Epoch 18/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5850 - accuracy: 0.6841 - precision: 0.6810 - recall: 0.6813\n",
            "Epoch 19/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5879 - accuracy: 0.6939 - precision: 0.6956 - recall: 0.6939\n",
            "Epoch 20/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5848 - accuracy: 0.6878 - precision: 0.6895 - recall: 0.6862\n",
            "Epoch 21/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5870 - accuracy: 0.6858 - precision: 0.6829 - recall: 0.6846\n",
            "Epoch 22/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5864 - accuracy: 0.6915 - precision: 0.6880 - recall: 0.6866\n",
            "Epoch 23/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5835 - accuracy: 0.6809 - precision: 0.6798 - recall: 0.6825\n",
            "Epoch 24/35\n",
            "77/77 [==============================] - 95s 1s/step - loss: 0.5805 - accuracy: 0.6959 - precision: 0.6963 - recall: 0.7000\n",
            "Epoch 25/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5852 - accuracy: 0.6841 - precision: 0.6857 - recall: 0.6882\n",
            "Epoch 26/35\n",
            "77/77 [==============================] - 95s 1s/step - loss: 0.5845 - accuracy: 0.6817 - precision: 0.6805 - recall: 0.6850\n",
            "Epoch 27/35\n",
            "77/77 [==============================] - 95s 1s/step - loss: 0.5833 - accuracy: 0.6850 - precision: 0.6834 - recall: 0.6825\n",
            "Epoch 28/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5805 - accuracy: 0.6858 - precision: 0.6860 - recall: 0.6882\n",
            "Epoch 29/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5791 - accuracy: 0.6902 - precision: 0.6902 - recall: 0.6919\n",
            "Epoch 30/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5765 - accuracy: 0.6943 - precision: 0.6975 - recall: 0.6935\n",
            "Epoch 31/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5820 - accuracy: 0.6797 - precision: 0.6828 - recall: 0.6825\n",
            "Epoch 32/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5790 - accuracy: 0.6870 - precision: 0.6879 - recall: 0.6846\n",
            "Epoch 33/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5795 - accuracy: 0.6866 - precision: 0.6876 - recall: 0.6846\n",
            "Epoch 34/35\n",
            "77/77 [==============================] - 96s 1s/step - loss: 0.5807 - accuracy: 0.6854 - precision: 0.6890 - recall: 0.6898\n",
            "Epoch 35/35\n",
            "77/77 [==============================] - 97s 1s/step - loss: 0.5840 - accuracy: 0.6878 - precision: 0.6848 - recall: 0.6846\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 35\n",
        "BATCH_SIZE = 32 \n",
        "# 32\n",
        "model.summary()\n",
        "print(len(X_train_ids_1))\n",
        "print(len(X_train_attention_1))\n",
        "# Train the model\n",
        "train_history1 = model.fit(\n",
        "    x = (X_train_ids_1, X_train_attention_1),\n",
        "    y = y_train,\n",
        "    epochs = EPOCHS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    # validation_data = ((X_test_ids, X_test_attention), y_test),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('distilbert1')\n",
        "# model.load_weights('distilbert1')\n",
        "\n",
        "\n",
        "model.evaluate((X_test_ids_1, X_test_attention_1), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0vyRZjw_K1J",
        "outputId": "03645fb9-bae9-4612-9944-9587d44557a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 23s 1s/step - loss: 0.5890 - accuracy: 0.7078 - precision: 0.7076 - recall: 0.7110\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.589024007320404, 0.7077922224998474, 0.7075929045677185, 0.7110389471054077]"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score,recall_score\n",
        "\n",
        "y_predicted = model.predict((X_test_ids_1, X_test_attention_1))\n",
        "y_predicted_modeled = tf.math.argmax(y_predicted,axis=1)\n",
        "print(np.unique(y_predicted_modeled))\n",
        "y_test_modeled =  tf.math.argmax(y_test,axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_test_modeled, y_predicted_modeled)\n",
        "print(cm)\n",
        "\n",
        "\n",
        "f1=f1_score(y_true= y_test_modeled, y_pred= y_predicted_modeled)\n",
        "\n",
        "#Print the accuracy\n",
        "print(f1)\n",
        "print(accuracy_score(y_true= y_test_modeled, y_pred= y_predicted_modeled))\n",
        "print(precision_score(y_true= y_test_modeled, y_pred= y_predicted_modeled, average='micro'))\n",
        "print(recall_score(y_true= y_test_modeled, y_pred= y_predicted_modeled, average='micro'))\n",
        "print(f1_score(y_true= y_test_modeled, y_pred= y_predicted_modeled,average='micro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqxhqfD2_uvt",
        "outputId": "4830d950-9ae3-47d8-fcfe-09299c6d3573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n",
            "[[358  38]\n",
            " [142  78]]\n",
            "0.4642857142857143\n",
            "0.7077922077922078\n",
            "0.7077922077922078\n",
            "0.7077922077922078\n",
            "0.7077922077922078\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DistilBert.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2681c61213f7868066ad62bb2a35fb330f9d31b463350b0be21ca9cb2599bc86"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}